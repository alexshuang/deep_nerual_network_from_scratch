{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "backward.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "VnWzX1s9LDEn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-OewEkEVX2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import fastai.datasets as datasets\n",
        "import gzip\n",
        "import pickle\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.nn.init as init\n",
        "import pdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qdt9mIkV2Ni",
        "colab_type": "code",
        "outputId": "eeb3c1e3-52cf-4565-ed7c-0d1e362044db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "MNIST_URL = 'http://deeplearning.net/data/mnist/mnist.pkl'\n",
        "fpath = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "\n",
        "with gzip.open(fpath, 'rb') as fp:\n",
        "  ((x_train, y_train), (x_val, y_val), _) = pickle.load(fp, encoding='latin-1')\n",
        "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 784), (50000,), (10000, 784), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpAQ__C4V2QA",
        "colab_type": "code",
        "outputId": "a8fedda1-a76d-48db-9340-3a661b7c38f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.mean(), x_train.std(), x_val.mean(), x_val.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.13044983, 0.3072898, 0.12865187, 0.3049646)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL7ca8s5ZeF7",
        "colab_type": "text"
      },
      "source": [
        "### Normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1TZ97yCV2Sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(x, m, s): return (x - m) / s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCXr9FhoZjUJ",
        "colab_type": "code",
        "outputId": "ef66557b-7a04-4e6d-97da-ced737245b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "m, s = x_train.mean(), x_train.std()\n",
        "x_train, x_val = norm(x_train, m, s), norm(x_val, m, s)\n",
        "x_val.mean(), x_val.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.005850922, 0.99243325)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEwdGApAdddn",
        "colab_type": "code",
        "outputId": "f4758fca-b8c4-4680-e3fd-a1a42045f377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "x_train[0], x_val[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.424517, -0.424517, -0.424517, -0.424517, ..., -0.424517, -0.424517, -0.424517, -0.424517], dtype=float32),\n",
              " array([-0.424517, -0.424517, -0.424517, -0.424517, ..., -0.424517, -0.424517, -0.424517, -0.424517], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuebIDUKctpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_val, y_val = map(torch.tensor, [x_train, y_train, x_val, y_val])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c3ytSKwaTZY",
        "colab_type": "text"
      },
      "source": [
        "### Model: linear -> relu -> linear -> mse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FZU19-0wo1F",
        "colab_type": "code",
        "outputId": "8b4fef86-dfcd-4169-8e1d-6c8e6511cec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def mse(y_hat, y):\n",
        "  return (y_hat.squeeze() - y.float()).pow(2).mean()\n",
        "\n",
        "def linear(x, w, b):\n",
        "  return x @ w + b\n",
        "\n",
        "def relu(x):\n",
        "  return x.clamp_min(0.) - 0.5\n",
        "\n",
        "def model(x):\n",
        "  x = relu(linear(x, W1, b1))\n",
        "  return linear(x, W2, b2)\n",
        "\n",
        "nh = [100, 100]\n",
        "W1 = torch.zeros(784, nh[0])\n",
        "b1 = torch.zeros(nh[0])\n",
        "W2 = torch.zeros(nh[0], 1)\n",
        "b2 = torch.zeros(1)\n",
        "\n",
        "init.kaiming_normal_(W1, mode='fan_out')\n",
        "init.kaiming_normal_(W2, mode='fan_out')\n",
        "y_hat = model(x_train)\n",
        "mse(y_hat, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(31.3463)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKMuZeahDeCu",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WlJtg__EqUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse_grad(outp, targ):\n",
        "  outp.g = 2 / outp.shape[0] * (outp.squeeze() - targ.float()).unsqueeze(-1)\n",
        "  \n",
        "def lin_grad(inp, outp, w, b):\n",
        "#   pdb.set_trace()\n",
        "  inp.g = outp.g @ w.t()\n",
        "  w.g = inp.t() @ outp.g\n",
        "  b.g = outp.g.sum(0)\n",
        "  \n",
        "def relu_grad(inp, outp):\n",
        "  inp.g = (inp > 0.).float() * outp.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcdDv4vhrUyH",
        "colab_type": "text"
      },
      "source": [
        "### Chain Rule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cP_tcyhEqMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_backward(x, y):\n",
        "  z1 = x @ W1 + b1\n",
        "  a1 = relu(z1)\n",
        "  outp = a1 @ W2 + b2\n",
        "  loss = mse(outp, y)\n",
        "  \n",
        "  mse_grad(outp, y)\n",
        "  lin_grad(a1, outp, W2, b2)\n",
        "  relu_grad(z1, a1)\n",
        "  lin_grad(x, z1, W1, b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU1KM6uAEprq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forward_backward(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCD8D-BaDmqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xg = x_train.g.clone()\n",
        "w1g = W1.g.clone()\n",
        "w2g = W2.g.clone()\n",
        "b1g = b1.g.clone()\n",
        "b2g = b2.g.clone()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDnHldLlGFRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x2 = x_train.clone().requires_grad_(True)\n",
        "w11 = W1.clone().requires_grad_(True)\n",
        "b11 = b1.clone().requires_grad_(True)\n",
        "w22 = W2.clone().requires_grad_(True)\n",
        "b22 = b2.clone().requires_grad_(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgxg61KQGGTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_backward2(x, y):\n",
        "  l1 = x @ w11 + b11\n",
        "  z1 = relu(l1)\n",
        "  outp = z1 @ w22 + b22\n",
        "  return mse(outp, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm3jDILWGGWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = forward_backward2(x_train, y_train)\n",
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w48sFR5eG_al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_near(a, b): return np.allclose(a, b)\n",
        "\n",
        "assert test_near(w1g, w11.grad)\n",
        "assert test_near(b1g, b11.grad)\n",
        "assert test_near(w2g, w22.grad)\n",
        "assert test_near(b2g, b22.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnWzX1s9LDEn",
        "colab_type": "text"
      },
      "source": [
        "### Refactor Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCtGwUiBG_d8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu():\n",
        "  def __call__(self, inp):\n",
        "    self.inp = inp\n",
        "    self.outp = inp.clamp_min(0.) - 0.5\n",
        "    return self.outp\n",
        "  \n",
        "  def backward(self):\n",
        "    self.inp.g = (self.inp > 0.).float() * self.outp.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HordHmQETaI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin():\n",
        "  def __init__(self, w, b):\n",
        "    self.w, self.b = w, b\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    self.inp = x\n",
        "    self.outp = x @ self.w + self.b\n",
        "    return self.outp\n",
        "  \n",
        "  def backward(self):\n",
        "    self.inp.g = self.outp.g @ self.w.t()\n",
        "    self.w.g = self.inp.t() @ self.outp.g\n",
        "    self.b.g = self.outp.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGvzx3wYTaqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MSE():\n",
        "  def __call__(self, inp, targ):\n",
        "    self.inp, self.targ = inp, targ\n",
        "    self.outp = (inp.squeeze() - targ.float()).pow(2).mean()\n",
        "    return self.outp\n",
        "  \n",
        "  def backward(self):\n",
        "    self.inp.g = 2 / self.inp.shape[0] * (self.inp.squeeze() - self.targ.float()).unsqueeze(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrkMxRBjTauY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "  def __init__(self, w1, b1, w2, b2):\n",
        "    self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
        "    self.loss_fn = MSE()\n",
        "    \n",
        "  def __call__(self, x, y):\n",
        "    for o in self.layers:\n",
        "      x = o(x)\n",
        "    return self.loss_fn(x, y)\n",
        "  \n",
        "  def backward(self):\n",
        "    self.loss_fn.backward()\n",
        "#     pdb.set_trace()\n",
        "    for o in reversed(self.layers):\n",
        "      o.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_p9bVfsTa0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nh = 100\n",
        "w1 = torch.zeros(784, nh)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.zeros(nh, 1)\n",
        "b2 = torch.zeros(1)\n",
        "\n",
        "init.kaiming_normal_(w1, mode='fan_out')\n",
        "init.kaiming_normal_(w2, mode='fan_out');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL2K_JHoTayh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = Model(w1, b1, w2, b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIONpmfiXsqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m(x_train, y_train)\n",
        "m.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDVwQ-6la86R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_backward2(x, y):\n",
        "  l1 = x @ w11 + b11\n",
        "  z1 = relu(l1)\n",
        "  outp = z1 @ w22 + b22\n",
        "  return mse(outp, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zklgdv-lbApj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x2 = x_train.clone().requires_grad_(True)\n",
        "w11 = w1.clone().requires_grad_(True)\n",
        "b11 = b1.clone().requires_grad_(True)\n",
        "w22 = w2.clone().requires_grad_(True)\n",
        "b22 = b2.clone().requires_grad_(True)\n",
        "\n",
        "loss = forward_backward2(x_train, y_train)\n",
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0pfHdv0bG5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = forward_backward2(x_train, y_train)\n",
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NMQkcjuZbi3",
        "colab_type": "code",
        "outputId": "a0a6d5e1-47c1-4977-ff44-ffca5d839517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(test_near(w1.g, w11.grad))\n",
        "print(test_near(b1.g, b11.grad))\n",
        "print(test_near(w2.g, w22.grad))\n",
        "print(test_near(b2.g, b22.grad))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_350W2UKa4cU",
        "colab_type": "code",
        "outputId": "0daa7d37-3f2c-4cc2-b7cd-2acd9e376bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%time m = Model(w1, b1, w2, b2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 198 µs, sys: 1.91 ms, total: 2.11 ms\n",
            "Wall time: 3.25 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCBrEkRRbRDj",
        "colab_type": "code",
        "outputId": "8f18a54d-7b82-4074-9ed6-e6b14fdaf92c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%time m(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 152 ms, sys: 976 µs, total: 153 ms\n",
            "Wall time: 156 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(25.1401)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8JdEvpAbUla",
        "colab_type": "code",
        "outputId": "08e7c38e-257f-432a-c590-08a5487e3c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%time m.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 279 ms, sys: 1.13 ms, total: 280 ms\n",
            "Wall time: 282 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nf04EqObUvM",
        "colab_type": "code",
        "outputId": "8f37d452-8d08-4b47-e693-fab1801f5fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%time loss = forward_backward2(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 152 ms, sys: 979 µs, total: 153 ms\n",
            "Wall time: 156 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ-qqDjWbUsn",
        "colab_type": "code",
        "outputId": "d7dd63fc-57e7-4cf9-b568-de8a2a494af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%time loss.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 157 ms, sys: 3.17 ms, total: 160 ms\n",
            "Wall time: 163 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il4c5nYLbUqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Module():\n",
        "  def __call__(self, *args):\n",
        "    self.args = args\n",
        "    self.outp = self.forward(*self.args)\n",
        "    return self.outp\n",
        "  \n",
        "  def forward(self, *args):\n",
        "    raise Exception('Not Implemented')\n",
        "    \n",
        "  def backward(self):\n",
        "    self.bwd(self.outp, *self.args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7AD6PmMuiXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu(Module):\n",
        "  def forward(self, x):\n",
        "    return x.clamp_min(0.) - 0.5\n",
        "  \n",
        "  def bwd(self, outp, inp):\n",
        "    inp.g = (inp > 0.).float() * outp.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHvfCe-lui0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin(Module):\n",
        "  def __init__(self, w, b):\n",
        "    self.w, self.b = w, b\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return x @ self.w + self.b\n",
        "  \n",
        "  def bwd(self, outp, inp):\n",
        "    self.w.g = inp.t() @ outp.g\n",
        "    inp.g = outp.g @ self.w.t()\n",
        "    self.b.g = outp.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fup37PxBui-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MSE(Module):\n",
        "  def forward(self, outp, targ):\n",
        "    return (outp.squeeze() - targ.float()).pow(2).mean()\n",
        "  \n",
        "  def bwd(self, outp, *args):\n",
        "    outp, targ = args\n",
        "    outp.g = 2 / outp.shape[0] * (outp.squeeze() - targ.float()).unsqueeze(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqB7Kdxqui7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(Module):\n",
        "  def __init__(self, w1, b1, w2, b2):\n",
        "    self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
        "    self.crit = MSE()\n",
        "    \n",
        "  def forward(self, x, y):\n",
        "    for o in self.layers:\n",
        "      x = o(x)\n",
        "    return self.crit(x, y)\n",
        "  \n",
        "  def bwd(self, outp, *args):\n",
        "    self.crit.backward()\n",
        "    for o in reversed(self.layers):\n",
        "      o.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRvrFkygui4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g, b1.g, w2.g, b2.g = [None] * 4\n",
        "m = Model(w1, b1, w2, b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paJM7Txs0zJI",
        "colab_type": "code",
        "outputId": "3f12a3ae-8d64-460c-8b97-7234e72e2d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%time loss = m(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 152 ms, sys: 962 µs, total: 153 ms\n",
            "Wall time: 156 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koAAk-0i0zwo",
        "colab_type": "code",
        "outputId": "a3250975-05ed-4c69-f4aa-2c99b470439b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%time m.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 285 ms, sys: 2.63 ms, total: 288 ms\n",
            "Wall time: 297 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cviUVI_a2aon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x2 = x_train.clone().requires_grad_(True)\n",
        "w11 = w1.clone().requires_grad_(True)\n",
        "b11 = b1.clone().requires_grad_(True)\n",
        "w22 = w2.clone().requires_grad_(True)\n",
        "b22 = b2.clone().requires_grad_(True)\n",
        "\n",
        "loss = forward_backward2(x_train, y_train)\n",
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4--fkat70z3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert test_near(w1.g, w11.grad)\n",
        "assert test_near(b1.g, b11.grad)\n",
        "assert test_near(w2.g, w22.grad)\n",
        "assert test_near(b2.g, b22.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFGpC-K4S_2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optim():\n",
        "  def __init__(self, lr, *parameters):\n",
        "    self.lr, self.parameters = lr, parameters\n",
        "  \n",
        "  def step(self):\n",
        "    for o in self.parameters:\n",
        "      o = o - self.lr * o.g\n",
        "  \n",
        "  def zero_grad(self):\n",
        "    for o in self.parameters:\n",
        "      o.g = 0."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwJCbfZWS_zo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_loop(x, y, model, crit, opt, bs=128, epoch=1):\n",
        "  for n in range(epoch):\n",
        "    nr_batch = math.ceil(x.shape[0] / bs)\n",
        "    for i in range(nr_batch):\n",
        "      start = bs * i\n",
        "      end = start + bs\n",
        "      x_batch = x[start:end]\n",
        "      y_batch = y[start:end]\n",
        "      outp = model(x_batch)\n",
        "      loss = crit(outp, y_batch)\n",
        "      if (i + 1) % 30 == 0:\n",
        "        print(\"mini-batch %d, loss: %.3f\" % (i + 1, loss))\n",
        "      opt.zero_grad()\n",
        "      crit.backward()\n",
        "      model.backward()\n",
        "      opt.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlUwI9PwS_wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(Module):\n",
        "  def __init__(self, w1, b1, w2, b2):\n",
        "    self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
        "    \n",
        "  def forward(self, x):\n",
        "    for o in self.layers:\n",
        "      x = o(x)\n",
        "    return x\n",
        "  \n",
        "  def bwd(self, outp, *args):\n",
        "    for o in reversed(self.layers):\n",
        "      o.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE4HGzImfUFk",
        "colab_type": "code",
        "outputId": "583a1d60-4f7e-42b4-83b0-79f42c307efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "lr = 1e-3\n",
        "m = Model(w1, b1, w2, b2)\n",
        "opt = Optim(lr, w1, b1, w2, b2)\n",
        "crit = MSE()\n",
        "\n",
        "train_loop(x_train, y_train, m, crit, opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mini-batch 30, loss: 27.630\n",
            "mini-batch 60, loss: 20.840\n",
            "mini-batch 90, loss: 24.904\n",
            "mini-batch 120, loss: 25.661\n",
            "mini-batch 150, loss: 25.589\n",
            "mini-batch 180, loss: 21.758\n",
            "mini-batch 210, loss: 26.606\n",
            "mini-batch 240, loss: 27.184\n",
            "mini-batch 270, loss: 22.656\n",
            "mini-batch 300, loss: 25.626\n",
            "mini-batch 330, loss: 27.401\n",
            "mini-batch 360, loss: 25.355\n",
            "mini-batch 390, loss: 25.346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyp8RDAh0z1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PytorchModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = [nn.Linear(784, 100), nn.ReLU(), nn.Linear(100, 1)]\n",
        "    self.crit = nn.MSELoss()\n",
        "    \n",
        "  def forward(self, x, y):\n",
        "    for o in self.layers:\n",
        "      x = o(x)\n",
        "    return self.crit(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_E_NOHn2_Gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pm = PytorchModel().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK9RsNQ73DfE",
        "colab_type": "code",
        "outputId": "c296c161-de0b-4a07-a6b6-0d09a21df488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "%time loss = pm(x_train, y_train.float())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:443: UserWarning: Using a target size (torch.Size([50000])) that is different to the input size (torch.Size([50000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.61 s, sys: 0 ns, total: 3.61 s\n",
            "Wall time: 3.62 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MpPxwEb3U1-",
        "colab_type": "code",
        "outputId": "985c3bc8-114c-4479-fc58-2ae6344045db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%time loss.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.34 s, sys: 49.7 ms, total: 9.39 s\n",
            "Wall time: 9.41 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sez21gTK5a18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = pm.layers[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6i0djmD5cOq",
        "colab_type": "code",
        "outputId": "d84ca947-6f05-4dbd-faeb-2d507397332c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "list(a.parameters())[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34RR3CXo3mBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}